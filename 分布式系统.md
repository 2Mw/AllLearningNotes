# 分布式系统

[TOC]

课程链接：

* [6.824 Schedule: Spring 2020 ](http://nil.csail.mit.edu/6.824/2020/schedule.html)
* [6.824 Schedule: Spring 2021](http://nil.csail.mit.edu/6.824/2021/schedule.html)，2021 添加了 lab 2D，设置更合理

推荐翻译：

* [Simviso MIT6.824 翻译](https://www.simtoco.com/#/albums?id=1000019)
* [MIT6.824 GItbook 翻译](https://mit-public-courses-cn-translatio.gitbook.io/mit6-824) 对应 Github [huihongxiao/MIT6.824](https://github.com/huihongxiao/MIT6.824)

## 一. MapReduce

MapReduce: 用户使用 `map` 函数根据键值对产生一系列的**过渡键值对**(intermediate key/value pairs)，然后根据 `reduce` 函数将具有相同过渡键(intermediate key)的过渡值(intermediate value)合并。

由于数据量十分庞大，只有在数百个或者数千个机器上进行计算才能在合理的时间内完成，然而中间产生的问题比如如何并行计算、分布存储数据、错误处理，都让本来简单的算法在分布式系统上需要很复杂的代码才能实现，并且代码过于晦涩难懂，因此产生了 MapReduce。

MapReduce 使用**函数式模型**(Functional Model)，隐藏了棘手的并行化、容错、数据分布以及负载均衡的细节，可以轻松地进行大规模并行计算，并且使用**再执行**(re-execution)作为原语机制进行容错。

### 1. 编程模型

计算就是根据输入的键值对来生成输出的键值对，MapReduce 有两个关键的函数即 `Map` 和 `Reduce`。假设 MapReduce 用来计数一堆文档中字母出现的次数。

* `Map` 函数，由用户进行编写，用于将输入键值对产生过渡键值对，MapReduce 库将具有相同过渡键的过渡值传递给 `Reduce` 函数。以计数为例，Map 函数伪代码可以写为：

  ```python
  def map(key, value):
      # key 文档名，value 文档内容
      for word in value:
          EmitIntermediate(word, "1");
  ```

  `Map` 函数所作工作相当于：`(k1, v1) -> list(k2, v2)`

* `Reduce` 函数，也是由用户进行编写，用于接收一个过渡键以及对应的一系列过渡值，然后将这些过渡值合并。通常情况下，每次 `Reduce` 函数调用返回 0 或 1 个值。以计数为例，Reduce 函数伪代码可以写为：

  ```python
  def reduce(key, values):
      # key 字母，values 表示 key 对应所有的过渡值
      res = 0
      for value in values:
          res += int(value)
      Emit(str(res))
  ```

  `Reduce` 函数所作工作相当于：`(k2, list(v2)) -> newvalue`

### 2. 执行细节

![image-20221005105038103](分布式系统.assets/image-20221005105038103.png)

<center><i>图1-1</i></center>

图1-1展示了 MapReduce 的整体流程图，当用户进程调用 MapReduce 的时：

1. 用户进程中的 MapReduce 库首先将输入文件划分为 $M$ 个 16 ~ 64 MB 的小文件，并且用户进程 fork 出众多子进程。
2. 其中 Master 进程是最特殊的，用来为其他子进程分配任务。划分为 $M$ 个小文件就有 $M$ 个 `Map` 任务，并且假设有 $R$ 个 `Reduce` 任务。Master 随机选取其中一个空闲 worker 来进行分配任务。
3. Map worker 从小文件中读取内容，从文件中解析键值对并且将其传给用户定义的 `Map` 函数，将 `Map` 函数产生的过渡键值对缓冲在内存中。
4. Map worker 会定期将缓冲的键值对写入本地磁盘，然后使用分区函数（比如 $hash(key)\%R$ ）将其分为 $R$ 份用于 reduce worker 进行处理。写入本地磁盘后将包含 $R$ 个临时文件的信息传递回 Master，然后 Master 将 `Map` 好的文件位置转发给 reduce worker。
5. 当 master 通知 reduce worker 过渡键值对的存储位置之后，reduce worker 通过 RPC 来读取数据。当 reduce worker 读取完所有过渡键值对会对其进行排序，这样相同 key 的数据就可以分组在一起。这里的排序工作是必要的，因为其他的键也会分配到相同的 reduce task 中，如果所需排序数据过于庞大，也可以使用外部排序。
6. reduce worker 为每个过渡键遍历所有过渡值，然后将 key 和所有的 values 都传递给用户定义的 `Reduce` 函数，然后将结果输出到这个 reduce task 分区中。
7. 当所有 map 和 reduce worker 结束之后，master 唤醒用户进程。

最终 reduce worker 产生了 $R$ 个输出文件，一般情况下用户不需要将这 $R$ 个输出文件合并，而是转入下一个 MapReduce 任务或者其他的分布式任务中。

🔵Master 的数据结构：

在 MapReduce 任务中，Master 起到很重要的枢纽作用，并且维护了几种数据结构。

* 对于每个 map 或者 reduce 任务都有三种状态：idle, in-process, completed. 

* 对于每个 worker 还应该有身份标识。
* 对于已完成的 map 任务，master 还应该保存 $R$ 个过渡键值对数据的位置和大小，然后将这些任务将给正在运行的 reduce worker。

### 3. 容错处理

由于 MapReduce 库是为成百上千个服务器处理大规模数据而设计的，因此容错能力必须好。在 MapReduce 任务中，可能出现 worker 故障和 master 故障。

* Master 故障

  由于 master 节点只有一个，==因此不太可能发生故障[^Q1]==，如果 master 故障 MR 任务会直接终止运算。master 节点也会定期向磁盘写入以上提到 master 数据结构信息的 checkpoint，因此当 master 故障恢复的时候可以从上一次状态继续运行。客户端如果遇到这种情况可以重新提交 MR 任务。

* Worker 故障

  Master 会定期向 worker 发送心跳包，如果在特定时间内 worker 未进行回应，master 会将 worker 标记为已故障。

  在 worker 上成功完成 map 或者 reduce 任务时应该重置为 idle 状态，worker 任务失败的时候也应该被重置为 idle 状态，方便进行重新调度。

  在 Map worker 上已完成的任务需要重新执行，因为 map 任务的结果存储在故障机器的硬盘上并且不可访问了，因此需要重新执行；==在 reduce worker 上已完成的任务不需要重新执行，因为其结果就保存在全局文件系统上[^Q2]==。

  如果一个集群中很多机器由于网络维护全部失联，MapReduce Master 会重新执行调度这些集群处理的任务，直到任务完成。

* 出现故障时候的处理机制

  在确定 map 和 reduce 函数都是确定性函数的时候，在不发生任何故障的情况下函数的在不同机器上的分布式实现产生的结果都是一致的。MapReduce 将 `Map` 和 `Reduce` 函数定义为原子性的，如果 master 重复收到已完成的 Map 任务信息，master 会选择忽略；否则 master 会将 $R$ 个文件的信息存放在其数据结构中。

> 还有一点需要注意的是，谷歌的 MR 任务是跑在其 Google File System 的基础上，当对于一堆大型文件进行 MR 任务处理的时候，在 GFS 各个机器上已经有文件的备份，因此无需占用额外的网络带宽。

如果 MR 任务中极个别 worker 上可能由于机器原因（网络带宽、CPU 占用过高、读写能力较差）导致整体任务执行时间变长，当 MR 任务进入末尾阶段，master 会将还在运行的任务进行备份执行（即在其他机器也运行），谷歌工程师发现如果开启备份执行会有效提高整体任务执行的速度。

## Appendix

[^Q1]: 为什么不太可能发生故障
[^Q2]: reduce worker 是执行在哪个机器上？