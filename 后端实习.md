# Go for intern

## 前言

推荐网站：

* 面经八股交流类网站
  1. [牛客网](https://www.nowcoder.com/)
  2. [CS-Notes](http://www.cyc2018.xyz/)：八股文的汇总
  3. [JavaGuide](https://javaguide.cn/)：不仅包含Java知识，还有其他
  4. [代码随想录](https://programmercarl.com/)：包含求职、面经、算法类的优秀总结
* 算法刷题类：
  1. [牛客网](https://www.nowcoder.com/)
  2. [力扣](https://leetcode-cn.com/problemset/algorithms/)
  3. [AcWing](https://www.acwing.com/)
* 推荐书籍：
  1. 深入理解Java虚拟机

## Java-JVM

参考：

* [java面试宝典](https://www.bilibili.com/video/BV15b4y117RJ)

### JVM内存结构

![image-20220302154931513](E:\Notes\实习求职\后端实习.assets\image-20220302154931513.png)

对于Java代码首先需要编译为Java字节码文件，然后通过java命令执行程序将对应的类加载进子系统。将类的方法信息加载到JVM中的方法区。创建好的实例对象存储到堆中，局部变量和方法参数引用都是存储到虚拟机栈中(JVM stacks)，对于一些特殊方法比如`hashcode()`需要存放到本地方法栈中。

如果切换线程的时候就需要使用到程序计数器，用来记录每个线程下一条的程序语句。

当使用的对象引用变量被设为null的时候，就需要垃圾回收来对其进行内存回收。对于字节码文件需要使用解释器解释为机器码，对于热点代码使用JIT即使编译器直接编译为机器码执行。

对于各个线程之间线程私有的结构是程序计数器和虚拟机栈，而线程共享的区域为堆和方法区。

### 垃圾回收算法

🔵普通的回收算法

1. 标记清除法：对于未被GCRoot引用的内存块进行标记，之后进行清除。效率高但是会产生碎片问题。
2. 标记整理法：在标记清除的基础上，采用紧凑的方法。无碎片但是效率比较低。
3. 标记复制法：将GCRoot引用的对象复制到新的区域。需要一块额外的内存。

🔵GC和分代垃圾回收算法

GC的要点：

* 回收的区域主要是**堆**区域
* 判断无用对象是根据可达性分析法、三色标记法标记存活对象。
* GC根据对象不同的生存时间采用分代垃圾回收算法，对于不同的对象采用不同的回收策略。

三色标记法：

![img](E:\Notes\实习求职\后端实习.assets\modb_20211010_4a3e36c4-296f-11ec-bd3f-38f9d3cd240d.png)

## Redis

### redis为什么这么快

参考：[15张图解：Redis的快可不是吹吹的](https://mp.weixin.qq.com/s/0R0Evh1QX5BPOQt9233vpQ)

<img src="https://mmbiz.qpic.cn/mmbiz_png/g6hBZ0jzZb0Zb0XiaaR6bGaN80wicXIIP735YhoW1fic47MuJOx0HheBX4ficULcmdHhdGQnqGcfCgvunMmxpb8LnA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

1. redis是基于内存实现的数据库，数据就存储在内存当中，减少了与磁盘之间的IO操作，因此速度很快。
2. 底层使用了高效的数据结构：比如双端链表、压缩列表、哈希表以及跳跃表等，使得数据存储的效率更高。
3. redis是单线程的，就避免了多线程之间切换CPU的上下文切换的开销。
4. redis采用的是I/O 多路复用模型同时监听客户端连接

### 缓存穿透、缓存击穿、缓存雪崩

🔵缓存穿透

缓存和数据库中都不存在对应的数据被大量请求。由于缓存中数据不存在，所有数据请求会直接穿透在数据库上。

原因：可能存在恶意请求爬虫以及黑客攻击。

解决：将对应null值的key缓存到数据库；逻辑层对不合理的请求进行拦截；使用布隆过滤器。

🔵缓存击穿

大量请求同时查询缓存中**某个**key，而这个key恰好失效了，导致大量请求打在数据库层。

原因：单个key为高热数据，恰好key过期

解决：延长key的失效时间或者设置为永久key；高峰期来临的时候刷新key的有效期；设置多级缓存。

🔵缓存雪崩

在较短的时间内，**大规模**的key缓存失效或者缓存服务器宕机了，导致大量的请求打在数据库上。

问题：大规模的key失效或者缓存服务器宕机

解决：对于key失效时间加上随机值；采用限流手段牺牲部分用户的体验来降低服务器的压力；根据业务类别对不同的key采用不同的失效策略。

### Redis如何持久化及其基本原理

参考：

* [Redis 面试全攻略、面试题大集合-0x7](https://mp.weixin.qq.com/s/6NobACeeKCcUy98Ikanryg)
* [Redis | rdb-持久化](http://www.cyc2018.xyz/数据库/Redis.html#rdb-持久化)

redis持久化的两种方式：RDB和AOF

🔵RDB(redis database)是将redis数据库快照以二进制的方式保存到硬盘中。

* 适合大规模的数据恢复，对数据库的完整性要求不大
* 在进行持久化的过程中需要fork子进程，很占用CPU。

`save`和`bgsave`命令

* save命令是阻塞式持久化，执行命令的时候，redis将数据全部持久化完毕后，才能处理其他命令。
* bgsave是非阻塞持久化，是创建子进程将内存中的数据写入RDB文件，期间可以执行其他命令。

🔵AOF(append of file)是将所有的写命令和参数追加到AOF文件中。

appendfsync选项：

|   选项   |         同步频率         |
| :------: | :----------------------: |
|  always  |     每个写命令都同步     |
| everysec |       每秒同步一次       |
|    no    | 让操作系统来决定何时同步 |

- always 选项会严重减低服务器的性能；
- everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；
- no 表示默认系统的缓存区写入磁盘的机制，不做程序强制，数据安全性和完整性差一些。

## MySQL

### 存储引擎

MySQL常用的有两类：InnoDB和MyISAM。

InnoDB支持事务处理，支持行锁和表锁；MyISAM不支持事务处理，MyISAM有很高的查询和插入性能，只支持表锁。

### 事务特性实现原理(ACID)

参考：[深入学习MySQL事务：ACID特性的实现原理](https://www.cnblogs.com/kismetv/p/10331633.html)

* 原子性(atomic)：即指事务是一个不可分割的单位，其中的操作要么全部执行，要么就都不执行。其实现是基于undolog(有了undo就能够回滚)。
* 一致性(Consistency)：数据库的完整性约束没有被破坏，事务执行前后都是合法的数据状态。其实现是**基于其他三个特性**。
* 隔离性(Isolation)：保证事务的执行尽量不受其他事务的影响。其实现是基于锁机制(保证写-写操作之间的隔离性)和MVCC(保证写-读操作之间的隔离性)。
* 持久性(Durable)：保证事务提交之后不会因为宕机等其他因素的影响而导致数据丢失。其实现主要是基于redolog。

### MVCC中事务隔离级别

参考：

* [彻底搞懂 MySQL 事务的隔离级别(优质)](https://developer.aliyun.com/article/743691)

MySQL中查询事务的隔离级别：`select @@transaction_isolation;`

四个隔离级别：

1. 未提交读(Read Uncommitted)：最低的隔离级别，允许读取其他事务中尚未提交的数据。可能会导致脏读，不可重复读和幻读。
2. 已提交读(Read Committed)：只允许读取事务提交后的数据，可阻止脏读，不可重复读和幻读不能阻止。
3. 可重复读(Repeatable-Read)：在同一个事务中，除非自己修改，对于**非范围型查询**的结果是一致的。幻读仍有可能发生(即范围型查询)
4. 可串行化(Serializable)：最高的隔离级别。所有的事务之间读操作添加表级共享锁，读写会互相阻塞，这样事务之间就完全不可能产生干扰，该级别可以防止四个并发问题。

### 并发事务中存在的四个问题

参考：

* [事务隔离级别(图文详解)](https://www.cnblogs.com/xzsj/p/xzsj-database-transaction.html)
* [深入学习MySQL事务：ACID特性的实现原理](https://www.cnblogs.com/kismetv/p/10331633.html)

1. 丢失数据（Lost to modify）

   两个事务同时对一个数据进行修改。比如现实生活中可能存在的信用卡双刷问题。

   |              Session 1              |             Session 2              |
   | :---------------------------------: | :--------------------------------: |
   |    select money from bank（200）    |   select money from bank（200）    |
   | update bank set money = money - 100 | update bank set money = money - 50 |
   |               （100）               |              （150）               |

   两个结果可能出现覆盖的情况，一个事务执行的结果相当于没有执行。

   解决方法：使用锁机制来进行加锁

2. 脏读（Dirty Read）

   一个事务读取了另一个未提交事务中的数据。

   |                    Session-1(RU)                     |              Session-2(RR)              |
   | :--------------------------------------------------: | :-------------------------------------: |
   | begin;<br/>select salary from t1 where id = 1;(5000) |                                         |
   |                                                      | update t1 set salary=4500 where id = 1; |
   |      ❌select salary from t1 where id = 1;(4500)      |                                         |
   |                                                      |                rollback;                |
   |      select salary from t1 where id = 1;(5000)       |                                         |

   处于Read-Uncommited模式下的会话一会出现脏读的情况。

3. 不可重复读（unrepeatable read）

   一个事务在RC读已提交隔离级别下，在同一事务内不同时间段读取到的数据不一致。在RC隔离级别下每次进行快照读(select)的时候都会生成新的readview；在RR隔离级别下只有第一次会生成新的readview。

   |                    Session-1(RC)                     |              Session-2(RR)              |
   | :--------------------------------------------------: | :-------------------------------------: |
   | begin;<br/>select salary from t1 where id = 1;(5000) |                                         |
   |                                                      | update t1 set salary=4500 where id = 1; |
   |      select salary from t1 where id = 1;(5000)       |                                         |
   |                                                      |                 commit;                 |
   |      ❌select salary from t1 where id = 1;(4500)      |                                         |
   |                       commit;                        |                                         |

4. 幻读(phantom read)

   幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，可能使用到了`insert` `delete` `update`语句更新了readview，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

   一般发现幻读的情况就是插入数据的时候发现`Duplicate key`的error，但是查询的时候却未出现对应的数据。

   解决方法：添加表锁。

不同隔离级别下可以解决的问题。

|     隔离级别     | 脏读 | 不可重复读 | 幻读 |
| :--------------: | :--: | :--------: | :--: |
| READ-UNCOMMITTED |  √   |     √      |  √   |
|  READ-COMMITTED  |  ×   |     √      |  √   |
| REPEATABLE-READ  |  ×   |     ×      |  √   |
|   SERIALIZABLE   |  ×   |     ×      |  ×   |

### 索引结构为什么使用B+树而不是B树

1. B+树的磁盘读写代价更小。B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，通常B+树矮更胖，高度小查询产生的I/O更少。
2. B+树查询效率更高。B+树使用双向链表串连所有叶子节点，区间查询效率更高（因为所有数据都在B+树的叶子节点，扫描数据库只需扫一遍叶子结点），但是B树则需要通过中序遍历才能完成查询范围的查找。
3. B+树查询效率更稳定。B+树每次都必须查询到叶子节点才能找到数据，而B树查询的数据可能不在叶子节点，也可能在，这样就会造成查询的效率的不稳定。

### 聚簇索引和非聚簇索引

参考：[聚簇索引与非聚簇索引（也叫二级索引）--最清楚的一篇讲解](https://cloud.tencent.com/developer/article/1541265)

- 聚簇索引：数据是和索引存放在一起的，找到索引也就找到了数据。主键索引的叶节点存储的是行数据，二级索引的叶节点存放的是对于存储行的主键值。

  当使用二级索引查找数据的时候，查找到叶节点拿到对应行的主键索引，再通过主键索引查找对应的行(**回表**)

- 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因
